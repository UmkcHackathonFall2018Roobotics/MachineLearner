import tensorflow as tf

from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

def conv_layer(input, channels_in, channels_out, name="conv"):
	with tf.name_scope(name):
		w = tf.Variable(tf.zeros([5,5,channels_in,channels_out]), name="W")
		b = tf.Variable(tf.zeros([channels_out]), name="B")
		conv = tf.nn.conv2d(input,w,strides=[1,1,1,1], padding="SAME")
		act = tf.nn.relu(conv+b)
		return tf.nn.max_pool(act, ksize=[1,1,1,1], strides = [1,2,2,1], padding = "SAME")

def fc_layer(input, channels_in, channels_out, name="fc"):
	with tf.name_scope(name):
		w = tf.Variable(tf.zeros([channels_in, channels_out]), name = "W")
		b = tf.Variable(tf.zeros([channels_out]), name = "B")
		return tf.nn.relu(tf.matmul(input, w )+ b)

# Setup placeholders, and reshape the data
x = tf.placeholder(tf.float32, shape = [None, 784], name="x")
x_image = tf.reshape(x,[-1, 28, 28, 1])
y = tf.placeholder(tf.float32, shape=[None, 10], name="labels")

conv1 = conv_layer(x_image, 1, 32, "conv1")
conv2 = conv_layer(conv1, 32, 64, "conv2")

flattened = tf.reshape(conv2, [-1, 7 * 7 * 64])
fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, "fc1")
logits = fc_layer(fc1, 1024, 10, "fc2")


with tf.name_scope("xent"):
	xent = tf.reduce_mean(tf.nn.softmax_cross_entrophy_with_logits(logits=logits, labels = y))
with tf.name_scope("train"):
	train_step = tf.train.AdamOptimizer(1e-4).minimize(xent)
with tf.name_scope("accuracy"):
	correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y,1))
	accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

writer = tf.summary.FileWriter("/Desktop/TensorBoardTest")
writer.add_graph(sess.graph)


